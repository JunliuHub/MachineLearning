{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息熵的基本理论\n",
    "决策树的基本原理就是根据一系列的判断条件给出‘是’或‘否’的结论，根据结果的不同进入不同的分支，最终得出结论或分类。如下图：\n",
    "![决策树流程图](http://img.blog.csdn.net/20140620103227953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHN6ZGg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "构造决策树的第一个问题是，当前数据集上的哪个特征在划分数据分类时起决定作用，也就是根据哪个属性来分类会更好呢？划分数据时我们每次只选择一个属性特征，如果训练集有20个特征，第一次选择哪个呢？所以我们要到对每个特征做出评估。\n",
    "\n",
    "在划分数据集前后信息发生的变化称为信息增益，获得信息增益最高的特征就是最好的选择，那么怎么度量信息而进一步的计算信息增益呢？-----信息熵\n",
    "\n",
    "集合信息的度量方式称为香农熵，或信息熵。\n",
    "\n",
    "怎么理解信息熵，见下面这篇引用：[谁能介绍一下信息熵是什么？](https://www.zhihu.com/question/22178202/answer/49929786)\n",
    ">让我们说人话！好的数学概念都应该是通俗易懂的。\n",
    "\n",
    ">信息熵，信息熵，怎么看怎么觉得这个“熵”字不顺眼，那就先不看。我们起码知道这个概念跟信息有关系。而它又是个数学模型里面的概念，一般而言是可以量化的。所以，第一个问题来了：信息是不是可以量化？\n",
    "\n",
    ">起码直觉上而言是可以的，不然怎么可能我们觉得有些人说的废话特别多，“没什么信息量”，有些人一语中的，一句话就传达了很大的信息量。\n",
    "\n",
    ">为什么有的信息量大有的信息量小？\n",
    "\n",
    ">有些事情本来不是很确定，例如明天股票是涨还是跌。如果你告诉我明天NBA决赛开始了，这两者似乎没啥关系啊，所以你的信息对明天股票是涨是跌带来的信息量很少。但是假如NBA决赛一开始，大家都不关注股票了没人坐庄股票有99%的概率会跌，那你这句话信息量就很大，因为本来不确定的事情变得十分确定。\n",
    "\n",
    ">而有些事情本来就很确定了，例如太阳从东边升起，你再告诉我一百遍太阳从东边升起，你的话还是丝毫没有信息量的，因为这事情不能更确定了。\n",
    "\n",
    ">所以说信息量的大小跟事情不确定性的变化有关。\n",
    "\n",
    ">那么，不确定性的变化跟什么有关呢？\n",
    "一，跟事情的可能结果的数量有关；二，跟概率有关。\n",
    "先说一。\n",
    "例如我们讨论太阳从哪升起。本来就只有一个结果，我们早就知道，那么无论谁传递任何信息都是没有信息量的。\n",
    "当可能结果数量比较大时，我们得到的新信息才有潜力拥有大信息量。\n",
    "\n",
    ">二，单看可能结果数量不够，还要看初始的概率分布。例如一开始我就知道小明在电影院的有15*15个座位的A厅看电影。小明可以坐的位置有225个，可能结果数量算多了。可是假如我们一开始就知道小明坐在第一排的最左边的可能是99%，坐其它位置的可能性微乎其微，那么在大多数情况下，你再告诉我小明的什么信息也没有多大用，因为我们几乎确定小明坐第一排的最左边了。\n",
    "\n",
    ">那么，怎么衡量不确定性的变化的大小呢？怎么定义呢？\n",
    "这个问题不好回答，但是假设我们已经知道这个量已经存在了，不妨就叫做信息量，那么你觉得信息量起码该满足些什么特点呢？\n",
    "\n",
    "\n",
    ">一，起码不是个负数吧，不然说句话还偷走信息呢~\n",
    "\n",
    ">二，起码信息量和信息量之间可以相加吧！假如你告诉我的第一句话的信息量是3，在第一句话的基础上又告诉我一句话，额外信息量是4，那么两句话信息量加起来应该等于7吧！难道还能是5是9？\n",
    "\n",
    ">三，刚刚已经提过，信息量跟概率有关系，但我们应该会觉得，信息量是连续依赖于概率的吧！就是说，某一个概率变化了0.0000001，那么这个信息量不应该变化很大。\n",
    "\n",
    ">四，刚刚也提过，信息量大小跟可能结果数量有关。假如每一个可能的结果出现的概率一样，那么对于可能结果数量多的那个事件，新信息有更大的潜力具有更大的信息量，因为初始状态下不确定性更大。\n",
    "\n",
    ">那有什么函数能满足上面四个条件呢？负的对数函数，也就是-log（x）！底数取什么都行。前面再随便乘个常数也行。\n",
    "a. 为什么不是正的？因为假如是正的，由于x是小于等于1的数，log（x）就小于等于0了。第一个特点满足。\n",
    "b. 咱们再来验证一下其他特点。三是最容易的。假如x是一个概率，那么log（x）是连续依赖于x的。done\n",
    "c。四呢？假如有n个可能结果，那么出现任意一个的概率是1/n，而-log(1/n)是n的增函数，没问题。\n",
    "d。最后验证二。由于-log(xy) = -log(x) -log(y)，所以也是对的。学数学的同学注意，这里的y可以是给定x的条件概率，当然也可以独立于x。\n",
    "\n",
    ">By the way，这个函数是唯一的（除了还可以多乘上任意一个常数），有时间可以自己证明一下，或者查书。\n",
    "\n",
    ">ok，所以我们知道一个事件的信息量就是这个事件发生的概率的负对数。\n",
    "\n",
    ">最后终于能回到信息熵。信息熵是跟所有可能性有关系的。每个可能事件的发生都有个概率。信息熵就是平均而言发生一个事件我们得到的信息量大小。所以数学上，信息熵其实是信息量的期望。（表达式参考其它答案或者看下面）\n",
    "H=-\\sum_{x\\epsilon U}{P(x)\\log P(x)}\n",
    "\n",
    ">至于为什么用“熵”这个怪字？大概是当时翻译的人觉得这个量跟热力学的熵有关系，所以就用了这个字，君不见字里头的火字旁？\n",
    "\n",
    ">而热力学为什么用这个字？这个真心不知道。。。\n",
    "\n",
    ">作者：滴水\n",
    "链接：https://www.zhihu.com/question/22178202/answer/49929786\n",
    "来源：知乎\n",
    ">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n",
    "\n",
    "简单说，我们要首先计算每一种可能性包含的信息量，然后计算集合所有可能性的信息量的期望值，即信息熵。\n",
    "\n",
    "## 信息熵的代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "        \n",
    "        shannonEnt = 0.0\n",
    "        for key in labelCounts:\n",
    "            prob = float(labelCounts[key]/numEntries)\n",
    "            shannonEnt -= prob*log(prob, 2)\n",
    "            \n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDat, labels = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "myDat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混合的数据越多，熵越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDat[0][-1] = 'mybe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
